{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part 1: Selecting Articles From Lexis-Nexis and Pre-processing</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the SQL query used to generate relevant results:\n",
    "\n",
    "`select title, source, content\n",
    "from 'gcp-cset-projects.gcp_cset_lexisnexis.raw_news'\n",
    "where (where source.name = \"The Times of India (TOI)\"\n",
    "or source.name = \"Epoch Times\"\n",
    "or source.name = \"The Epoch Times\"\n",
    "or source.name = \"The New York Times\"\n",
    "or source.name = \"Global Times (China)\"\n",
    "or source.name = \"South China Morning Post\")\n",
    "and language = “English”\n",
    "and id in (select id from gcp_cset_lexisnexis.unique_article_ids)\n",
    "and regexp_contains(title, r\"(?i)\\b(?:chin(a|ese)|beijing|ccp)\\b\")`\n",
    "\n",
    "Results of this query —> mrm311_sandbox.china_pubs_regexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import openai\n",
    "openai.api_key = \"[ACCESS KEY GOES HERE]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54089\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rocketing fares 'little help' for stricken air...</td>\n",
       "      <td>South China Morning Post</td>\n",
       "      <td>Airfares to the mainland soared in the past fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Killer who cut up tycoon into 108 pieces sente...</td>\n",
       "      <td>South China Morning Post</td>\n",
       "      <td>A killer who chopped a tycoon from China into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Year too far for many athletes; For the likes ...</td>\n",
       "      <td>South China Morning Post</td>\n",
       "      <td>Not all athletes were able to prolong their ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resistance hardens against china; Beijing now ...</td>\n",
       "      <td>South China Morning Post</td>\n",
       "      <td>When Australia first proposed an international...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why enigma of the black hands is tired narrati...</td>\n",
       "      <td>South China Morning Post</td>\n",
       "      <td>US diplomats and politicians talk endlessly ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  rocketing fares 'little help' for stricken air...   \n",
       "1  Killer who cut up tycoon into 108 pieces sente...   \n",
       "2  Year too far for many athletes; For the likes ...   \n",
       "3  resistance hardens against china; Beijing now ...   \n",
       "4  Why enigma of the black hands is tired narrati...   \n",
       "\n",
       "                     source                                            content  \n",
       "0  South China Morning Post  Airfares to the mainland soared in the past fe...  \n",
       "1  South China Morning Post  A killer who chopped a tycoon from China into ...  \n",
       "2  South China Morning Post  Not all athletes were able to prolong their ca...  \n",
       "3  South China Morning Post  When Australia first proposed an international...  \n",
       "4  South China Morning Post  US diplomats and politicians talk endlessly ab...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull results into a dataframe\n",
    "\n",
    "df = pd.read_gbq(\"\"\"select *\n",
    "                    from `gcp-cset-projects.mrm311_sandbox.china_pubs_regexed`\"\"\",\n",
    "                 dialect='standard', project_id='gcp-cset-projects')\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54089\n",
      "50992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "source\n",
       "South China Morning Post    17975\n",
       "Global Times (China)        13197\n",
       "The New York Times           7458\n",
       "The Times of India (TOI)     5435\n",
       "The Epoch Times              3515\n",
       "Epoch Times                  3412\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates and see the breakdown by source\n",
    "\n",
    "print(len(df))\n",
    "df = df.drop_duplicates('title')\n",
    "print(len(df))\n",
    "\n",
    "df.value_counts('source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>source_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rocketing fares 'little help' for stricken air...</td>\n",
       "      <td>South China Morning Post</td>\n",
       "      <td>Airfares to the mainland soared in the past fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Killer who cut up tycoon into 108 pieces sente...</td>\n",
       "      <td>South China Morning Post</td>\n",
       "      <td>A killer who chopped a tycoon from China into ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Year too far for many athletes; For the likes ...</td>\n",
       "      <td>South China Morning Post</td>\n",
       "      <td>Not all athletes were able to prolong their ca...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resistance hardens against china; Beijing now ...</td>\n",
       "      <td>South China Morning Post</td>\n",
       "      <td>When Australia first proposed an international...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why enigma of the black hands is tired narrati...</td>\n",
       "      <td>South China Morning Post</td>\n",
       "      <td>US diplomats and politicians talk endlessly ab...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  rocketing fares 'little help' for stricken air...   \n",
       "1  Killer who cut up tycoon into 108 pieces sente...   \n",
       "2  Year too far for many athletes; For the likes ...   \n",
       "3  resistance hardens against china; Beijing now ...   \n",
       "4  Why enigma of the black hands is tired narrati...   \n",
       "\n",
       "                     source  \\\n",
       "0  South China Morning Post   \n",
       "1  South China Morning Post   \n",
       "2  South China Morning Post   \n",
       "3  South China Morning Post   \n",
       "4  South China Morning Post   \n",
       "\n",
       "                                             content  source_num  \n",
       "0  Airfares to the mainland soared in the past fe...           4  \n",
       "1  A killer who chopped a tycoon from China into ...           4  \n",
       "2  Not all athletes were able to prolong their ca...           4  \n",
       "3  When Australia first proposed an international...           4  \n",
       "4  US diplomats and politicians talk endlessly ab...           4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inconsistent naming for the Epoch Times makes it convenient to use a source_num instead of source\n",
    "\n",
    "source_to_source_num = {'Global Times (China)': 0,\n",
    "                        'Epoch Times': 1,\n",
    "                        'The Epoch Times': 1,\n",
    "                        'The New York Times': 2,\n",
    "                        'The Times of India (TOI)': 3,\n",
    "                        'South China Morning Post': 4}\n",
    "\n",
    "source_num_to_source = {0: 'Global Times',\n",
    "                       1: 'Epoch Times',\n",
    "                       2: 'New York Times',\n",
    "                       3: 'Times of India', \n",
    "                       4: 'South China\\nMorning Post'}\n",
    "\n",
    "df['source_num'] = [source_to_source_num[source] for source in df.source]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text by removing links, lowercasing, and lemmatizer\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def regex(text):\n",
    "    text = re.sub('http\\S+', ' ', text)\n",
    "    text = re.sub('[^a-zA-z]', ' ', text)\n",
    "    return text.lower()\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\s+', text)\n",
    "    tokens = [tok for tok in tokens if tok not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "def lemmatize(tokens):\n",
    "    lemms = [lemmatizer.lemmatize(tok) for tok in tokens]\n",
    "    return lemms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-26 14:44:56.682666\n",
      "2021-04-26 14:45:05.595197\n",
      "2021-04-26 14:46:08.023452\n",
      "2021-04-26 14:46:08.053004\n",
      "2021-04-26 14:46:08.075995\n",
      "50992\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>source_num</th>\n",
       "      <th>regexed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>title_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rocketing fares 'little help' for stricken air...</td>\n",
       "      <td>South China Morning Post</td>\n",
       "      <td>Airfares to the mainland soared in the past fe...</td>\n",
       "      <td>4</td>\n",
       "      <td>airfares to the mainland soared in the past fe...</td>\n",
       "      <td>[airfares, mainland, soared, past, weeks, coro...</td>\n",
       "      <td>422</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Killer who cut up tycoon into 108 pieces sente...</td>\n",
       "      <td>South China Morning Post</td>\n",
       "      <td>A killer who chopped a tycoon from China into ...</td>\n",
       "      <td>4</td>\n",
       "      <td>a killer who chopped a tycoon from china into ...</td>\n",
       "      <td>[killer, chopped, tycoon, china, pieces, vanco...</td>\n",
       "      <td>309</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Year too far for many athletes; For the likes ...</td>\n",
       "      <td>South China Morning Post</td>\n",
       "      <td>Not all athletes were able to prolong their ca...</td>\n",
       "      <td>4</td>\n",
       "      <td>not all athletes were able to prolong their ca...</td>\n",
       "      <td>[athletes, able, prolong, careers, next, summe...</td>\n",
       "      <td>278</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>resistance hardens against china; Beijing now ...</td>\n",
       "      <td>South China Morning Post</td>\n",
       "      <td>When Australia first proposed an international...</td>\n",
       "      <td>4</td>\n",
       "      <td>when australia first proposed an international...</td>\n",
       "      <td>[australia, first, proposed, international, in...</td>\n",
       "      <td>423</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why enigma of the black hands is tired narrati...</td>\n",
       "      <td>South China Morning Post</td>\n",
       "      <td>US diplomats and politicians talk endlessly ab...</td>\n",
       "      <td>4</td>\n",
       "      <td>us diplomats and politicians talk endlessly ab...</td>\n",
       "      <td>[us, diplomats, politicians, talk, endlessly, ...</td>\n",
       "      <td>388</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  rocketing fares 'little help' for stricken air...   \n",
       "1  Killer who cut up tycoon into 108 pieces sente...   \n",
       "2  Year too far for many athletes; For the likes ...   \n",
       "3  resistance hardens against china; Beijing now ...   \n",
       "4  Why enigma of the black hands is tired narrati...   \n",
       "\n",
       "                     source  \\\n",
       "0  South China Morning Post   \n",
       "1  South China Morning Post   \n",
       "2  South China Morning Post   \n",
       "3  South China Morning Post   \n",
       "4  South China Morning Post   \n",
       "\n",
       "                                             content  source_num  \\\n",
       "0  Airfares to the mainland soared in the past fe...           4   \n",
       "1  A killer who chopped a tycoon from China into ...           4   \n",
       "2  Not all athletes were able to prolong their ca...           4   \n",
       "3  When Australia first proposed an international...           4   \n",
       "4  US diplomats and politicians talk endlessly ab...           4   \n",
       "\n",
       "                                             regexed  \\\n",
       "0  airfares to the mainland soared in the past fe...   \n",
       "1  a killer who chopped a tycoon from china into ...   \n",
       "2  not all athletes were able to prolong their ca...   \n",
       "3  when australia first proposed an international...   \n",
       "4  us diplomats and politicians talk endlessly ab...   \n",
       "\n",
       "                                              tokens  word_count  title_len  \n",
       "0  [airfares, mainland, soared, past, weeks, coro...         422        195  \n",
       "1  [killer, chopped, tycoon, china, pieces, vanco...         309        143  \n",
       "2  [athletes, able, prolong, careers, next, summe...         278        129  \n",
       "3  [australia, first, proposed, international, in...         423        135  \n",
       "4  [us, diplomats, politicians, talk, endlessly, ...         388        195  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create columns holding the various stages of pre-processed text\n",
    "# Also create a column for the word count (in post-preprocessing tokens) and title length (in characters)\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "df['regexed'] = df['content'].apply(lambda x: regex(x))\n",
    "print(datetime.datetime.now())\n",
    "df['tokens'] = df['regexed'].apply(lambda x: tokenize(x))\n",
    "print(datetime.datetime.now())\n",
    "df['word_count'] = df['tokens'].apply(lambda x: len(x))\n",
    "print(datetime.datetime.now())\n",
    "df['title_len'] = df['title'].apply(lambda x: len(x))\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36099\n"
     ]
    }
   ],
   "source": [
    "# Restrict to articles with an effective word count between 100 and 500 words\n",
    "\n",
    "df = df[df['word_count'] > 100]\n",
    "df = df[df['word_count'] < 500]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_num\n",
       "4    13146\n",
       "0    10327\n",
       "3     4838\n",
       "1     4632\n",
       "2     3156\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many articles now exist from each source \n",
    "\n",
    "df.value_counts('source_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>source_num</th>\n",
       "      <th>regexed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>title_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China inspires the true hustler in me</td>\n",
       "      <td>Global Times (China)</td>\n",
       "      <td>Illustration: Luo Xuan/GT\\n\\n\\n\\nWho knew that...</td>\n",
       "      <td>0</td>\n",
       "      <td>illustration  luo xuan gt    who knew that aft...</td>\n",
       "      <td>[illustration, luo, xuan, gt, knew, studying, ...</td>\n",
       "      <td>277</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nepal PM's China visit puts ties on a new road</td>\n",
       "      <td>Global Times (China)</td>\n",
       "      <td>Illustration: Liu Rui/GT\\n\\n\\n\\nDuring Nepales...</td>\n",
       "      <td>0</td>\n",
       "      <td>illustration  liu rui gt    during nepalese pr...</td>\n",
       "      <td>[illustration, liu, rui, gt, nepalese, prime, ...</td>\n",
       "      <td>427</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China's delivery evolution under coronavirus</td>\n",
       "      <td>Global Times (China)</td>\n",
       "      <td>An SF Express plane Photo: IC\\n\\n\\n\\nWu Lian, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>an sf express plane photo  ic    wu lian  a de...</td>\n",
       "      <td>[sf, express, plane, photo, ic, wu, lian, deli...</td>\n",
       "      <td>445</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flights between China and S. Korea expected to...</td>\n",
       "      <td>Global Times (China)</td>\n",
       "      <td>A flight parks at Jeju International Airport i...</td>\n",
       "      <td>0</td>\n",
       "      <td>a flight parks at jeju international airport i...</td>\n",
       "      <td>[flight, parks, jeju, international, airport, ...</td>\n",
       "      <td>184</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China to protect own rights against US tariffs...</td>\n",
       "      <td>Global Times (China)</td>\n",
       "      <td>China will take effective measures to firmly s...</td>\n",
       "      <td>0</td>\n",
       "      <td>china will take effective measures to firmly s...</td>\n",
       "      <td>[china, take, effective, measures, firmly, saf...</td>\n",
       "      <td>204</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                source  \\\n",
       "0              China inspires the true hustler in me  Global Times (China)   \n",
       "1     Nepal PM's China visit puts ties on a new road  Global Times (China)   \n",
       "2       China's delivery evolution under coronavirus  Global Times (China)   \n",
       "3  Flights between China and S. Korea expected to...  Global Times (China)   \n",
       "4  China to protect own rights against US tariffs...  Global Times (China)   \n",
       "\n",
       "                                             content  source_num  \\\n",
       "0  Illustration: Luo Xuan/GT\\n\\n\\n\\nWho knew that...           0   \n",
       "1  Illustration: Liu Rui/GT\\n\\n\\n\\nDuring Nepales...           0   \n",
       "2  An SF Express plane Photo: IC\\n\\n\\n\\nWu Lian, ...           0   \n",
       "3  A flight parks at Jeju International Airport i...           0   \n",
       "4  China will take effective measures to firmly s...           0   \n",
       "\n",
       "                                             regexed  \\\n",
       "0  illustration  luo xuan gt    who knew that aft...   \n",
       "1  illustration  liu rui gt    during nepalese pr...   \n",
       "2  an sf express plane photo  ic    wu lian  a de...   \n",
       "3  a flight parks at jeju international airport i...   \n",
       "4  china will take effective measures to firmly s...   \n",
       "\n",
       "                                              tokens  word_count  title_len  \n",
       "0  [illustration, luo, xuan, gt, knew, studying, ...         277         37  \n",
       "1  [illustration, liu, rui, gt, nepalese, prime, ...         427         46  \n",
       "2  [sf, express, plane, photo, ic, wu, lian, deli...         445         44  \n",
       "3  [flight, parks, jeju, international, airport, ...         184         91  \n",
       "4  [china, take, effective, measures, firmly, saf...         204         54  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Randomly sample 3,000 articles from each publication\n",
    "\n",
    "df = df.groupby('source_num').sample(n=3000, replace=False)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>source_num</th>\n",
       "      <th>regexed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>title_len</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China inspires the true hustler in me</td>\n",
       "      <td>Global Times (China)</td>\n",
       "      <td>Illustration: Luo Xuan/GT\\n\\n\\n\\nWho knew that...</td>\n",
       "      <td>0</td>\n",
       "      <td>illustration  luo xuan gt    who knew that aft...</td>\n",
       "      <td>[illustration, luo, xuan, gt, knew, studying, ...</td>\n",
       "      <td>277</td>\n",
       "      <td>37</td>\n",
       "      <td>[illustration, luo, xuan, gt, knew, studying, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nepal PM's China visit puts ties on a new road</td>\n",
       "      <td>Global Times (China)</td>\n",
       "      <td>Illustration: Liu Rui/GT\\n\\n\\n\\nDuring Nepales...</td>\n",
       "      <td>0</td>\n",
       "      <td>illustration  liu rui gt    during nepalese pr...</td>\n",
       "      <td>[illustration, liu, rui, gt, nepalese, prime, ...</td>\n",
       "      <td>427</td>\n",
       "      <td>46</td>\n",
       "      <td>[illustration, liu, rui, gt, nepalese, prime, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>China's delivery evolution under coronavirus</td>\n",
       "      <td>Global Times (China)</td>\n",
       "      <td>An SF Express plane Photo: IC\\n\\n\\n\\nWu Lian, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>an sf express plane photo  ic    wu lian  a de...</td>\n",
       "      <td>[sf, express, plane, photo, ic, wu, lian, deli...</td>\n",
       "      <td>445</td>\n",
       "      <td>44</td>\n",
       "      <td>[sf, express, plane, photo, ic, wu, lian, deli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Flights between China and S. Korea expected to...</td>\n",
       "      <td>Global Times (China)</td>\n",
       "      <td>A flight parks at Jeju International Airport i...</td>\n",
       "      <td>0</td>\n",
       "      <td>a flight parks at jeju international airport i...</td>\n",
       "      <td>[flight, parks, jeju, international, airport, ...</td>\n",
       "      <td>184</td>\n",
       "      <td>91</td>\n",
       "      <td>[flight, park, jeju, international, airport, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>China to protect own rights against US tariffs...</td>\n",
       "      <td>Global Times (China)</td>\n",
       "      <td>China will take effective measures to firmly s...</td>\n",
       "      <td>0</td>\n",
       "      <td>china will take effective measures to firmly s...</td>\n",
       "      <td>[china, take, effective, measures, firmly, saf...</td>\n",
       "      <td>204</td>\n",
       "      <td>54</td>\n",
       "      <td>[china, take, effective, measure, firmly, safe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                source  \\\n",
       "0              China inspires the true hustler in me  Global Times (China)   \n",
       "1     Nepal PM's China visit puts ties on a new road  Global Times (China)   \n",
       "2       China's delivery evolution under coronavirus  Global Times (China)   \n",
       "3  Flights between China and S. Korea expected to...  Global Times (China)   \n",
       "4  China to protect own rights against US tariffs...  Global Times (China)   \n",
       "\n",
       "                                             content  source_num  \\\n",
       "0  Illustration: Luo Xuan/GT\\n\\n\\n\\nWho knew that...           0   \n",
       "1  Illustration: Liu Rui/GT\\n\\n\\n\\nDuring Nepales...           0   \n",
       "2  An SF Express plane Photo: IC\\n\\n\\n\\nWu Lian, ...           0   \n",
       "3  A flight parks at Jeju International Airport i...           0   \n",
       "4  China will take effective measures to firmly s...           0   \n",
       "\n",
       "                                             regexed  \\\n",
       "0  illustration  luo xuan gt    who knew that aft...   \n",
       "1  illustration  liu rui gt    during nepalese pr...   \n",
       "2  an sf express plane photo  ic    wu lian  a de...   \n",
       "3  a flight parks at jeju international airport i...   \n",
       "4  china will take effective measures to firmly s...   \n",
       "\n",
       "                                              tokens  word_count  title_len  \\\n",
       "0  [illustration, luo, xuan, gt, knew, studying, ...         277         37   \n",
       "1  [illustration, liu, rui, gt, nepalese, prime, ...         427         46   \n",
       "2  [sf, express, plane, photo, ic, wu, lian, deli...         445         44   \n",
       "3  [flight, parks, jeju, international, airport, ...         184         91   \n",
       "4  [china, take, effective, measures, firmly, saf...         204         54   \n",
       "\n",
       "                                              lemmas  \n",
       "0  [illustration, luo, xuan, gt, knew, studying, ...  \n",
       "1  [illustration, liu, rui, gt, nepalese, prime, ...  \n",
       "2  [sf, express, plane, photo, ic, wu, lian, deli...  \n",
       "3  [flight, park, jeju, international, airport, s...  \n",
       "4  [china, take, effective, measure, firmly, safe...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finish pre-processing by lemmatizing the tokens for each article\n",
    "# NOTE: this was not done previously because it is more efficient to do it when the results are pared down\n",
    "\n",
    "df['lemmas'] = df['tokens'].apply(lambda x: lemmatize(x))\n",
    "\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a .csv for future work\n",
    "# All future code should use this .csv instead of re-running the previous code\n",
    "# This avoids randomness in the sampling above from carrying over into the results\n",
    "\n",
    "df.to_csv('china_articles_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part Two: Create GPT-3 Outputs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "      <th>source_num</th>\n",
       "      <th>regexed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>title_len</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>China urges greater efforts to ease Korean ten...</td>\n",
       "      <td>Global Times (China)</td>\n",
       "      <td>China hopes all parties would do more to ease ...</td>\n",
       "      <td>0</td>\n",
       "      <td>china hopes all parties would do more to ease ...</td>\n",
       "      <td>['china', 'hopes', 'parties', 'would', 'ease',...</td>\n",
       "      <td>276</td>\n",
       "      <td>51</td>\n",
       "      <td>['china', 'hope', 'party', 'would', 'ease', 't...</td>\n",
       "      <td>china hope party would ease tension korean pen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multilateral cooperation involving China best ...</td>\n",
       "      <td>Global Times (China)</td>\n",
       "      <td>The US and several Western powers including Au...</td>\n",
       "      <td>0</td>\n",
       "      <td>the us and several western powers including au...</td>\n",
       "      <td>['us', 'several', 'western', 'powers', 'includ...</td>\n",
       "      <td>273</td>\n",
       "      <td>79</td>\n",
       "      <td>['u', 'several', 'western', 'power', 'includin...</td>\n",
       "      <td>u several western power including australia su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Despite pandemic at home, US continues to make...</td>\n",
       "      <td>Global Times (China)</td>\n",
       "      <td>Illustration: Liu Rui/GT\\n\\n\\n\\nOver the last ...</td>\n",
       "      <td>0</td>\n",
       "      <td>illustration  liu rui gt    over the last two ...</td>\n",
       "      <td>['illustration', 'liu', 'rui', 'gt', 'last', '...</td>\n",
       "      <td>377</td>\n",
       "      <td>67</td>\n",
       "      <td>['illustration', 'liu', 'rui', 'gt', 'last', '...</td>\n",
       "      <td>illustration liu rui gt last two week u govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cut Chinese firms in eye of the storm a break:...</td>\n",
       "      <td>Global Times (China)</td>\n",
       "      <td>Photo: IC\\n\\n\\n\\n\\nAccording to Reuters, Chine...</td>\n",
       "      <td>0</td>\n",
       "      <td>photo  ic     according to reuters  chinese le...</td>\n",
       "      <td>['photo', 'ic', 'according', 'reuters', 'chine...</td>\n",
       "      <td>438</td>\n",
       "      <td>69</td>\n",
       "      <td>['photo', 'ic', 'according', 'reuters', 'chine...</td>\n",
       "      <td>photo ic according reuters chinese leading chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finnair launches new flight services for China</td>\n",
       "      <td>Global Times (China)</td>\n",
       "      <td>Lars Olofsson, Greater China sales director at...</td>\n",
       "      <td>0</td>\n",
       "      <td>lars olofsson  greater china sales director at...</td>\n",
       "      <td>['lars', 'olofsson', 'greater', 'china', 'sale...</td>\n",
       "      <td>361</td>\n",
       "      <td>46</td>\n",
       "      <td>['lars', 'olofsson', 'greater', 'china', 'sale...</td>\n",
       "      <td>lars olofsson greater china sale director finn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                source  \\\n",
       "0  China urges greater efforts to ease Korean ten...  Global Times (China)   \n",
       "1  Multilateral cooperation involving China best ...  Global Times (China)   \n",
       "2  Despite pandemic at home, US continues to make...  Global Times (China)   \n",
       "3  Cut Chinese firms in eye of the storm a break:...  Global Times (China)   \n",
       "4     Finnair launches new flight services for China  Global Times (China)   \n",
       "\n",
       "                                             content  source_num  \\\n",
       "0  China hopes all parties would do more to ease ...           0   \n",
       "1  The US and several Western powers including Au...           0   \n",
       "2  Illustration: Liu Rui/GT\\n\\n\\n\\nOver the last ...           0   \n",
       "3  Photo: IC\\n\\n\\n\\n\\nAccording to Reuters, Chine...           0   \n",
       "4  Lars Olofsson, Greater China sales director at...           0   \n",
       "\n",
       "                                             regexed  \\\n",
       "0  china hopes all parties would do more to ease ...   \n",
       "1  the us and several western powers including au...   \n",
       "2  illustration  liu rui gt    over the last two ...   \n",
       "3  photo  ic     according to reuters  chinese le...   \n",
       "4  lars olofsson  greater china sales director at...   \n",
       "\n",
       "                                              tokens  word_count  title_len  \\\n",
       "0  ['china', 'hopes', 'parties', 'would', 'ease',...         276         51   \n",
       "1  ['us', 'several', 'western', 'powers', 'includ...         273         79   \n",
       "2  ['illustration', 'liu', 'rui', 'gt', 'last', '...         377         67   \n",
       "3  ['photo', 'ic', 'according', 'reuters', 'chine...         438         69   \n",
       "4  ['lars', 'olofsson', 'greater', 'china', 'sale...         361         46   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  ['china', 'hope', 'party', 'would', 'ease', 't...   \n",
       "1  ['u', 'several', 'western', 'power', 'includin...   \n",
       "2  ['illustration', 'liu', 'rui', 'gt', 'last', '...   \n",
       "3  ['photo', 'ic', 'according', 'reuters', 'chine...   \n",
       "4  ['lars', 'olofsson', 'greater', 'china', 'sale...   \n",
       "\n",
       "                                              joined  \n",
       "0  china hope party would ease tension korean pen...  \n",
       "1  u several western power including australia su...  \n",
       "2  illustration liu rui gt last two week u govern...  \n",
       "3  photo ic according reuters chinese leading chi...  \n",
       "4  lars olofsson greater china sale director finn...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the .csv generated in Part One\n",
    "\n",
    "df = pd.read_csv('china_articles_cleaned.csv')\n",
    "df['joined'] = df['lemmas'].apply(lambda x: ' '.join(eval(x)))\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "source_num\n",
       "4    25\n",
       "3    25\n",
       "2    25\n",
       "1    25\n",
       "0    25\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First select 25 headlines from each source where the headline is between 75 and 125 characters long\n",
    "\n",
    "headlines_df = df[df['title_len'] > 75]\n",
    "headlines_df = headlines_df[headlines_df['title_len'] < 125]\n",
    "print(len(headlines_df))\n",
    "headlines_df = headlines_df.groupby('source_num').sample(n=25, replace=False)\n",
    "headlines = headlines_df.title.tolist()\n",
    "\n",
    "headlines_df.value_counts('source_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to store headline:output pairs\n",
    "\n",
    "# Note the parameters: default amount of randomness by setting temperature to 0.7, non-default frequency penalty\n",
    "# of 0.2 to prevent repetitive lists, and a max_token length of 400\n",
    "\n",
    "gpt3 = pd.DataFrame(headlines, columns=['title'])\n",
    "\n",
    "def call_gpt3(headline):\n",
    "    prompt = headline+'\\n'\n",
    "    response_full = openai.Completion.create(engine='davinci', prompt=prompt, max_tokens=400, n=1, temperature=0.7, frequency_penalty=0.2)\n",
    "    response = response_full.get('choices')[0].text.strip()\n",
    "    return response\n",
    "\n",
    "outputs = []\n",
    "for i in range(len(headlines)):\n",
    "    outputs.append(call_gpt3(headlines[i]))\n",
    "    if (i+1) % 10 == 0:\n",
    "        print('{} iterations completed at {}.'.format(i+1, datetime.datetime.now()))\n",
    "\n",
    "gpt3['output'] = outputs\n",
    "\n",
    "gpt3.to_csv('gpt3_outputs.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
