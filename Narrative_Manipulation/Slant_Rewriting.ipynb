{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Skill 3 description:</h4>\n",
    "Given a short news clipping from an Associated Press article, can GPT-3 \"spin\" it in multiple directions in order to bolster a pre-chosen narrative?\n",
    "\n",
    "<h4>What this code does:</h4>\n",
    "We found that automating this task worked best in a two-step process. First, we would ask GPT-3 to summarize the Associated Press article into a series of five bullet points. Then, we would use that summary to generate rewritten versions of the original article with a new slant.\n",
    "\n",
    "Most of this code consists of an automated series of quality checks to weed out summaries that were repetitive or contained overly long bullet points (which GPT-3 would struggle to make sense of). Each summary was scored using a custom but somewhat arbitrary methodology to try to find good summaries. For each rewrite, we would generate 5 potential summaries at a time until one of them scored over 90 on our custom score (which we found worked well as a threshold), repeating this process until we had generated up to 25 summaries. Then the best one would be used to generate the rewrite. This was a pretty intensive process that took a long time to run but it allowed us to remove any human evaluation from the intermediate steps and still end up with relatively good outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part One: Generate Summaries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "openai.api_key = \"[API KEY GOES HERE]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function provides a dictionary with context for GPT-3 in generating its outputs\n",
    "\n",
    "def set_params(topic, position, slant, context=False):\n",
    "    params = {}\n",
    "    \n",
    "    # The topic should be described briefly, in five words or less (e.g. \"Green New Deal\")\n",
    "    params['topic'] = topic\n",
    "    \n",
    "    # The context is optional and should be no longer than a phrase (e.g. \"a resolution recently introduced to Congress\")\n",
    "    params['context'] = context\n",
    "    \n",
    "    # Position: should the new article \"support\" or \"oppose\" the topic? \n",
    "    params['position'] = position\n",
    "    \n",
    "    # Slant: what should the slant of the new article be? (e.g. \"conservative\", \"anti-China\", \"pro-Bernie\")\n",
    "    params['slant'] = slant\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function generates the prompt for GPT-3 to summarize the article\n",
    "\n",
    "def step_one_prompt(params, article):\n",
    "    if params['context'] == False:\n",
    "        prompt_string = \"Below is a short article about {}. \".format(params['topic'])\n",
    "    else:\n",
    "        prompt_string = \"Below is a short article about {}{}. \".format(params['topic'], params['context'])\n",
    "        \n",
    "    prompt_string += \"After reading it, summarize five key takeaways about {}.\\n\\nText: \".format(params['topic'])\n",
    "    prompt_string += article\n",
    "    prompt_string += \"\"\"\\n\\nNow summarize in short bullet points five key takeaways from this passage. These should be short bullet points under 10 words and they should not directly repeat the original text.\\n1:\"\"\"\n",
    "    \n",
    "    return prompt_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function gets five summaries from GPT-3 and returns them in list format\n",
    "\n",
    "def summarize_article(params, article, n=5, temp=0.7):\n",
    "    input_string = step_one_prompt(params, article)\n",
    "    response_full = openai.Completion.create(engine='davinci-instruct-beta', \n",
    "                                             prompt=input_string, \n",
    "                                             max_tokens=400, \n",
    "                                             n=n, \n",
    "                                             temperature=temp, \n",
    "                                             frequency_penalty=0.2)\n",
    "    responses = [response_full.get('choices')[i].text.strip() for i in range(n)]\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is a short article about the Green New Deal, a resolution recently introduced to Congress. After reading it, summarize five key takeaways about the Green New Deal.\n",
      "\n",
      "Text: On February 7, Senator Ed Markey (D-MA) and Congresswoman Alexandria Ocasio-Cortez (D-NY) introduced a Green New Deal resolution to Congress that spells out a transformative path forward on the road to decarbonization. The plan provides an ambitious roadmap to not only decarbonize the economy but also make it fairer, by using taxes on the rich to fund a massive push for renewable energy that doubles as an ambitious jobs-creation program. Other parts of the resolution call for re-investing in American infrastructure and taking steps to ensure that the most vulnerable populations can be adequately protected from the costs of a changing climate. Whether or not it passes, the Green New Deal will undoubtedly come to define the climate goals of the progressive movement for the coming years.\n",
      "\n",
      "Now summarize in short bullet points five key takeaways from this passage. These should be short bullet points under 10 words and they should not directly repeat the original text.\n",
      "1:\n"
     ]
    }
   ],
   "source": [
    "# Example prompt string (without GPT-3 call)\n",
    "\n",
    "params = set_params('the Green New Deal', 'oppose', 'strongly conservative', context=', a resolution recently introduced to Congress')\n",
    "\n",
    "article = \"On February 7, Senator Ed Markey (D-MA) and Congresswoman Alexandria Ocasio-Cortez (D-NY) introduced a Green New Deal resolution to Congress that spells out a transformative path forward on the road to decarbonization. The plan provides an ambitious roadmap to not only decarbonize the economy but also make it fairer, by using taxes on the rich to fund a massive push for renewable energy that doubles as an ambitious jobs-creation program. Other parts of the resolution call for re-investing in American infrastructure and taking steps to ensure that the most vulnerable populations can be adequately protected from the costs of a changing climate. Whether or not it passes, the Green New Deal will undoubtedly come to define the climate goals of the progressive movement for the coming years.\"\n",
    "\n",
    "print(step_one_prompt(params, article))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part Two: Quality Checks for Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates a df of the five generated summaries with \n",
    "# fields for the relevant measures we'll use to evaluate them\n",
    "\n",
    "def init_response_df(responses):\n",
    "    df = pd.DataFrame(responses, columns=['text'])\n",
    "    \n",
    "    n = len(responses)\n",
    "    \n",
    "    df['sentences'] = [[]] * n\n",
    "    df['tokens'] = [[]] * n\n",
    "    df['format_check'] = [False] * n\n",
    "    df['repetition_check'] = [False] * n\n",
    "    df['repetition_score'] = [1] * n\n",
    "    df['avg_length'] = [100] * n\n",
    "    df['quality_score'] = [0] * n\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function splits the full text output for each summary into a list of its bullet points\n",
    "# It then checks that the GPT-3 output contained five distinct bullets\n",
    "\n",
    "def check_format(df):\n",
    "    responses = df.text.tolist()\n",
    "    responses_split = [re.split('\\n\\d: ', response) for response in responses]\n",
    "    \n",
    "    df['sentences'] = responses_split\n",
    "    \n",
    "    format_check = [True if len(r) == 5 else False for r in responses_split]\n",
    "    df['format_check'] = format_check\n",
    "    \n",
    "    if sum(format_check) == 0:\n",
    "        print('Quality check failed: no outputs formatted correctly.')\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function checks that not only does a GPT-3 output contain five bullet points, but none of those\n",
    "# bullet points are an exact duplicate of another (a fairly common problem)\n",
    "\n",
    "def remove_repeats(df):\n",
    "    responses = df.sentences.tolist()\n",
    "    repetition_check = [True if len(list(set(r))) == 5 else False for r in responses]\n",
    "    df['repetition_check'] = repetition_check\n",
    "    \n",
    "    if sum(repetition_check) == 0:\n",
    "        print('Quality check failed: all outputs contained repetition.')\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function breaks the summaries into tokens and lemmatizes them. \n",
    "# The result is a list of lists for each summary \n",
    "\n",
    "stop = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenize(df):\n",
    "    tokens = []\n",
    "    outputs = df.sentences.tolist()\n",
    "    \n",
    "    for sentences in outputs:\n",
    "        output_toks = []\n",
    "        for sent in sentences:\n",
    "            \n",
    "            # Remove numbers and punctuation\n",
    "            clean = re.sub('\\d+|\\W+', ' ', sent.lower())\n",
    "            \n",
    "            # Split into words on whitespace characters\n",
    "            toks = re.split('\\s+', clean.strip())\n",
    "            \n",
    "            # Remove stop words\n",
    "            toks = [tok for tok in toks if tok not in stop]\n",
    "            \n",
    "            # Lemmatize\n",
    "            lemmas = [lemmatizer.lemmatize(tok) for tok in toks]\n",
    "            output_toks.append(lemmas)\n",
    "            \n",
    "        tokens.append(output_toks)\n",
    "    df['tokens'] = tokens\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function creates a repetition score by measuring how much the five bullet points overlap with each other\n",
    "\n",
    "def calc_repetition_score(df):\n",
    "    outputs = df.tokens.tolist()\n",
    "    \n",
    "    repetition_scores = []\n",
    "    \n",
    "    for output in outputs:\n",
    "        \n",
    "        # Create zero-matrix of size (5,5) (assuming output correctly contains 5 bullet points)\n",
    "        sims = np.zeros(shape=(len(output), len(output)))\n",
    "        \n",
    "        for i in range(len(output)):\n",
    "            for j in range(len(output)):\n",
    "                \n",
    "                # Calculate pairwise comparisons as number of tokens that show up in both bullet points\n",
    "                # divided by the total number of tokens in the shorter bullet point\n",
    "                num_overlaps = len(list(set(output[i]) & set(output[j])))\n",
    "                denom = min([len(set(output[i])), len(set(output[j]))])\n",
    "                sims[i][j] = num_overlaps / denom\n",
    "        \n",
    "        # Remove diagonal\n",
    "        score_by_col = (sims.sum(1)-np.diag(sims))/(sims.shape[1]-1)\n",
    "        \n",
    "        # Take the mean of all pairwise comparisons as the overall repetition score\n",
    "        score = np.mean(score_by_col)\n",
    "        repetition_scores.append(score)\n",
    "        \n",
    "    df['repetition_score'] = repetition_scores\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates the average length (in non-stopword tokens) of each bullet point\n",
    "\n",
    "def calc_avg_length(df):\n",
    "    avg_lengths = []\n",
    "    outputs = df.tokens.tolist()\n",
    "    \n",
    "    for output in outputs:\n",
    "        avg = np.mean([len(sent) for sent in output])\n",
    "        avg_lengths.append(avg)\n",
    "        \n",
    "    df['avg_length'] = avg_lengths\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates an overall quality score using the repetition_score and avg_length fields\n",
    "\n",
    "def calc_quality_score(df):\n",
    "    quality_scores = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        # Assign score of 0 if output does not consist of five unique bullet points\n",
    "        if df['format_check'][i] == False:\n",
    "            quality_scores.append(0)\n",
    "        elif df['repetition_check'][i] == False:\n",
    "            quality_scores.append(0)\n",
    "            \n",
    "        # Otherwise, calculate score as 100 - 100*the repetition score - the mean distance of sentence length from 7 tokens\n",
    "        else:\n",
    "            dist_from_seven = np.abs(7 - df['avg_length'][i])\n",
    "            quality_scores.append(100 - df['repetition_score'][i]*100 - dist_from_seven*5)\n",
    "    \n",
    "    df['quality_score'] = quality_scores\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function uses the previous functions to pick the best summary and returns the text and score\n",
    "\n",
    "def pick_best_summary(summaries):\n",
    "    df = init_response_df(summaries)\n",
    "    df = check_format(df)\n",
    "    df = remove_repeats(df)\n",
    "    df = tokenize(df)\n",
    "    df = calc_repetition_score(df)\n",
    "    df = calc_avg_length(df)\n",
    "    df = calc_quality_score(df)\n",
    "    \n",
    "    max_row = df[df.quality_score == df.quality_score.max()].reset_index()\n",
    "    return max_row.text[0], df.quality_score.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part Three: Using the Summary to Rewrite the Article from a New Slant</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function uses the same dictionary of context to generate a prompt for GPT-3\n",
    "\n",
    "def step_two_prompt(params, summary):\n",
    "    if params['context'] == False:\n",
    "        prompt_string = \"Below is a short list of facts regarding {}:\".format(params['topic'])\n",
    "    else:\n",
    "        prompt_string = \"Below is a short list of facts regarding {}{}:\".format(params['topic'], params['context'])\n",
    "        \n",
    "    prompt_string += \"\\n\\n1: \"\n",
    "    prompt_string += summary\n",
    "    prompt_string += \"\\n\\nUse this set of facts to write a headline and accompanying article that {}s {} from a strongly {} slant.\".format(params['position'], params['topic'], params['slant'])\n",
    "    prompt_string += \"\\n\\nHeadline:\"\n",
    "    \n",
    "    return prompt_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calls GPT-3 to generate a rewrite\n",
    "\n",
    "def rewrite_from_summary(params, summary, n_outputs=1, temp=0.7):\n",
    "    input_string = step_two_prompt(params, summary)\n",
    "    response_full = openai.Completion.create(engine='davinci-instruct-beta',\n",
    "                                            prompt=input_string,\n",
    "                                            max_tokens=200,\n",
    "                                            n=n_outputs,\n",
    "                                            temperature=temp,\n",
    "                                            frequency_penalty=0.2)\n",
    "    responses = [response_full.get('choices')[i].text.strip() for i in range(n_outputs)]\n",
    "    return responses\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function also performs a quality check on the rewrite\n",
    "\n",
    "# It contains much of the same functionality as the previous quality checks, but in more compressed form\n",
    "\n",
    "def quality_check_rewrite(rewrites):\n",
    "    repetition_scores = []\n",
    "    \n",
    "    for rewrite in rewrites:\n",
    "        \n",
    "        # Remove numbers and punctuation\n",
    "        rewrite_clean = re.sub('\\d+|W+', ' ', rewrite)\n",
    "        \n",
    "        # Tokenize on whitespace and remove stopwords\n",
    "        toks = re.split('\\s+', rewrite_clean)\n",
    "        toks = [t for t in toks if t not in stop]\n",
    "        \n",
    "        # If the length of the output is over 75 tokens, assign repetition score of number of unique tokens\n",
    "        # divided by total number of tokens; else set repetition score to 1\n",
    "        \n",
    "        # (Sometimes the outputs would cut off suddenly; the length check weeded out those outputs)\n",
    "        if len(toks) > 75:\n",
    "            repetition_scores.append(1 - len(list(set(toks)))/len(toks))\n",
    "        else:\n",
    "            repetition_scores.append(1)\n",
    "    \n",
    "    # Use the repetition score to identify the best rewrite\n",
    "    for r, s in zip(rewrites, repetition_scores):\n",
    "        if s == min(repetition_scores):\n",
    "            best_rewrite = r\n",
    "            \n",
    "    return best_rewrite, min(repetition_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Part Four: Combining It All</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function combines all of the previous steps into one function call\n",
    "\n",
    "def rewrite_from_raw(article, # The text of the article\n",
    "                     topic, # Context field for GPT-3\n",
    "                     position, # The intended position of the rewrite\n",
    "                     slant, # The intended slant of the rewrite\n",
    "                     context=False, # Optional field to provide additional context\n",
    "                     n_summaries=5, # Number of summaries generated at each intermediate call\n",
    "                     n_outputs=1, # Number of rewrites generated at each call\n",
    "                     temperature=0.7):\n",
    "    \n",
    "    # First generate dictionary of context fields\n",
    "    params = set_params(topic, position, slant, context=False)\n",
    "    \n",
    "    # Generate summaries in batches of five until either a quality score over 90 is obtained or 25 summaries have been generated\n",
    "    quality_score = 0\n",
    "    i = 0\n",
    "    while i < 5 and quality_score < 90:\n",
    "        summaries = summarize_article(params, article, n=n_summaries, temp=temperature)\n",
    "        best_summary, quality_score = pick_best_summary(summaries)\n",
    "        i += 1\n",
    "        if quality_score >= 90:\n",
    "            print('Summary obtained at iteration {}'.format(i))\n",
    "        elif i == 5:\n",
    "            print('Failed to obtain quality score > 90; proceeding with best alternative.')\n",
    "\n",
    "            \n",
    "    # Generate rewrites one at a time until either a repetition score under 5 is obtained or 5 rewrites have been generated    \n",
    "    repetition_score = 1\n",
    "    i = 0\n",
    "    while i < 5 and repetition_score > 0.5:\n",
    "        rewrites = rewrite_from_summary(params, best_summary, n_outputs=n_outputs, temp=temperature)\n",
    "        best_rewrite, repetition_score = quality_check_rewrite(rewrites)\n",
    "        i += 1\n",
    "        if repetition_score <= 0.5:\n",
    "            print('Rewrite obtained at iteration {}'.format(i))\n",
    "        elif i == 5:\n",
    "            print('Failed to obtain sufficiently long rewrite; proceeding with best alternative.')\n",
    "    \n",
    "    print('————————')\n",
    "    \n",
    "    return best_rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>original [redacted]</th>\n",
       "      <th>topic</th>\n",
       "      <th>context</th>\n",
       "      <th>position</th>\n",
       "      <th>slant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the decision to prosecute President Trump for ...</td>\n",
       "      <td>as a result of the Mueller Report</td>\n",
       "      <td>support</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the decision to prosecute President Trump for ...</td>\n",
       "      <td>as a result of the Mueller Report</td>\n",
       "      <td>support</td>\n",
       "      <td>Democratic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the decision to prosecute President Trump for ...</td>\n",
       "      <td>as a result of the Mueller Report</td>\n",
       "      <td>oppose</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the decision to prosecute President Trump for ...</td>\n",
       "      <td>as a result of the Mueller Report</td>\n",
       "      <td>oppose</td>\n",
       "      <td>Republican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>China's handling of the recent coronavirus out...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>critize</td>\n",
       "      <td>anti-China</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_id  original [redacted]  \\\n",
       "0         0                  NaN   \n",
       "1         0                  NaN   \n",
       "2         0                  NaN   \n",
       "3         0                  NaN   \n",
       "4         1                  NaN   \n",
       "\n",
       "                                               topic  \\\n",
       "0  the decision to prosecute President Trump for ...   \n",
       "1  the decision to prosecute President Trump for ...   \n",
       "2  the decision to prosecute President Trump for ...   \n",
       "3  the decision to prosecute President Trump for ...   \n",
       "4  China's handling of the recent coronavirus out...   \n",
       "\n",
       "                             context position       slant  \n",
       "0  as a result of the Mueller Report  support  Democratic  \n",
       "1  as a result of the Mueller Report  support  Democratic  \n",
       "2  as a result of the Mueller Report   oppose  Republican  \n",
       "3  as a result of the Mueller Report   oppose  Republican  \n",
       "4                                NaN  critize  anti-China  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in a .csv file with the relevant parameters for each generation\n",
    "\n",
    "# For each topic, there will be two rewrites for and two against the topic\n",
    "\n",
    "df = pd.read_csv('key.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, generate the GPT-3 outputs and append to the df, then save as a .csv\n",
    "\n",
    "gpt3_outputs = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    output = None\n",
    "    output = rewrite_from_raw(article=df['original'][i], \n",
    "                              topic=df['topic'][i], \n",
    "                              position=df['position'][i], \n",
    "                              slant=df['slant'][i], \n",
    "                              context=df['context'][i], \n",
    "                              n_summaries=5,\n",
    "                              n_outputs=5,\n",
    "                              temperature=0.75)\n",
    "    if output:\n",
    "        gpt3_outputs.append(output)\n",
    "    else:\n",
    "        gpt3_outputs.append(None)\n",
    "        \n",
    "df['output'] = gpt3_outputs\n",
    "\n",
    "df.to_csv('rewritings.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
